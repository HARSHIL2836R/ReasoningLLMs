### April 7
Tried running `t5-small`,`facebook/opt-1.3b` and `openai-community/gpt2` but all gave wrong answers, 0% accuracy. Will have to go through code and check for more models.  

### April 11
optillm is an OpenAI API compatible _optimizing inference proxy_ which implements several state-of-the-art techniques that can improve the accuracy and performance of LLMs.  
Inference proxy is a software layer that sits between the LLM and the application, allowing for optimization of the LLM's performance and accuracy.  
It can be used to improve the performance of LLMs by optimizing the way they process and generate text.

